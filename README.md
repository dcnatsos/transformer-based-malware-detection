# Transformer-Based Malware Detection using Process Resource Utilization Metrics
This repository contains sets of experiments that fine-tune and compare the LSTM architecture with a custom Transformer architecture in the scope of multivariate series classification. The series are comprised of processes at a given system snapshot, expressed as a set of performance (resource utilization) metrics. The dataset used for these experiments is the Small (infected only VM) [Cloud Malware - VMs Performance Metrics Dataset 2019, Mahmoud Abdelsalam](http://www.mabdelsalam.com/downloads.html).

## INFO
- _Experiment series_ contain the 10 experiments each one performing a 10-fold cross validation with different split, to compare the LSTM with the Transformer architectures. These results can then be aggregated using the _aggregate_results.py_ script.
- There are three experiment series: 1/1, 1/10, 1/100 denoting the number of samples used from the original dataset. The experiments of the latter two, use, apart from a different split from one another, a different sample from the original dataset, i.e., in 1/10 experiment series, each experiment draws a different 10% sample from the original dataset and creates a new random split to perform 10-fold cross validation.
- _Tuning_ contains the tuning experiments of the two models (LSTM and Transformer)
- Legacy experiments comparing the two models or training them separately can be found in _training_transformers_, _transformer_vs_lstm_ and _checkpoints/_, _logs/_ and _images/_.
- _Limitation:_ For the most part the comprehension of the code was sacrificed in the sake of speed.
