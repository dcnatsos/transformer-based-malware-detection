import os
import pandas as pd
from sklearn.model_selection import train_test_split
import math
import numpy as np

# Define Training, Validation, Test sizes
SAMPLE_NO = 8
TRAIN_SIZE = math.floor(SAMPLE_NO*0.6)
VALIDATION_SIZE = math.ceil(SAMPLE_NO*0.2)
TEST_SIZE = math.ceil(SAMPLE_NO*0.2)

if TRAIN_SIZE + VALIDATION_SIZE + TEST_SIZE != SAMPLE_NO:
    raise Exception(f"Bad dataset size:\nSample Number: {SAMPLE_NO}\nTrain Size: {TRAIN_SIZE}\nValidation Size: {VALIDATION_SIZE}\nTest Size: {TEST_SIZE}")

# Read each preprocessed CSV file representing an experiment
data_path = os.path.join(os.getcwd(), 'preprocessed')
csv_files = os.listdir(data_path)[:SAMPLE_NO] # Use only the first SAMPLE_NO (for testing the training.py)
dfs = [pd.read_csv(os.path.join(data_path, file)) for file in csv_files] # A list of dfs, 1 csv = 1 df

# Drop specified columns from all dataframes
columns_to_drop = [
'sample_no', 'exp_no', 'vm_id', 'pid', 'ppid', 'process_creation_time', 'gid_real',
'gid_saved', 'mem_pss', #'experiment_id' , 'sample_time', 'label' # These three are dropped later
] 

# Drop unecessary columns
for df in dfs:
    df.drop(columns=columns_to_drop, inplace=True)

# Split labels into a different df?


# Split data by experiment into training, validation, and testing sets
train_experiments, test_experiments = train_test_split(csv_files, test_size=(TEST_SIZE+VALIDATION_SIZE), random_state=42)
val_experiments, test_experiments = train_test_split(test_experiments, test_size=TEST_SIZE, random_state=42)

print('Train:', train_experiments)
print('Validation', val_experiments)
print('Test:', test_experiments)

# Collect data for each set and transform into series format
datasets = {}
for split, experiments in zip(["train", "val", "test"], [train_experiments, val_experiments, test_experiments]): # (('train', [1, 2]), ('val', [3]), ('test', [4]))
    
    # data contains the concatenated train/validation/test dataframe in the respective iteration (3 iterations)
    data = pd.concat([dfs[csv_files.index(exp)] for exp in experiments]) 
    
    # series_data = []
    # for experiment_id, df in data.groupby('experiment_id'): # Per each dataframe (train,validation,test) group by experiment id
    #     snapshots = df.groupby('sample_time') # And then group by sample time per each experiment
    #     series = []
    #     for timestamp, group in snapshots:
    #         series.append(group.drop(columns=['sample_time', 'experiment_id']).values.tolist())
    #     series_data.append((series, df['label'].iloc[0]))  # Append a tuple containing series data and label
    
    # datasets[split] = series_data

    series_data = []
    for experiment_id, df in data.groupby('experiment_id'): # Per each dataframe (train, validation, test) group by experiment id
        snapshots = df.groupby('sample_time') # And then group by sample time per each experiment
        for timestamp, group in snapshots:

            # Check if all labels within the snapshot are the same
            if group['label'].nunique() > 1:
                raise ValueError("Snapshot contains different labels")
            
            # Determine the class label for the snapshot
            label = 1 if any(group['label']) else 0
            
            # Append a tuple containing series data and label
            series = group.drop(columns=['sample_time', 'experiment_id', 'label']).values.tolist()
            series_data.append((series, label))

    datasets[split] = series_data

    if len(datasets[split]) != pd.concat([dfs[csv_files.index(exp)] for exp in experiments])['sample_time'].unique().size:
        raise ValueError(f"Series sample number are not the same for split: {split}")

    print(f'Split: {split} sample size: ',len(datasets[split]))


"""
    - datasets -> dict: A dictionary containing the data splitted in training, validation, test set
    - datasets.train/val/test -> list: A list of tuples, each one containing:
    - datasets.train/val/test[i][0] -> list: snapshot/subsamples list of the i-th tuple/snapshot
    - datasets.train/val/test[i][1] -> int: label of the i-th tuple/snapshot
    - datasets.train/val/test[i][j][0] -> int: feature vector of the j-th process and the i-th tuple/snapshot

    -- Each tuple refers to a specific snapshot on a given timestamp of the system processes. The label of the tuple
    states whether the system was infected at that time or not. 
    -- (the concept of experiment_id is used up until splitting
    into train/validation/test where all the snapshots from the same experiment are maintained within one of train/val/test
    and not splitted. After that, the experiment_id concept is deprecated)
    -- The infectious process is probably the one that has the same name with the csv -> TODO: Implement this later.
"""

print('Datasets keys: ', datasets.keys())
print(type(datasets['val'])) # Validation List
print(len(datasets['val']))
print(type(datasets['val'][0])) # A snapshot/sample tuple (subsamples list, label)
print(len(datasets['val'][0]))
print(type(datasets['val'][0][0])) # Subsamples list
print(len(datasets['val'][0][0]))
print(type(datasets['val'][0][0][0])) # Feature vector of a specific process at a specific timestamp/snapshot/sample
print(len(datasets['val'][0][0][0]))
datasets['train'][0][0]



def prepare_data(data):
  """
  Prepares data for LSTM training.

  Args:
      data: A list of tuples containing (series, label).
          - series: A list of lists, where each inner list represents features 
                    of all processes at a specific timestamp within the snapshot.
          - label: An integer representing the class label (0 or 1) for the entire snapshot.

  Returns:
      A tuple containing two numpy arrays:
          - X: Input data for the LSTM, shaped (samples, feature_dim).
          - y: Labels, shaped (samples,).
  """
  X, y = [], []
  for series, label in data:
    # Get the number of features per process (assuming all processes have the same)
    feature_dim = len(series[0])
    # The entire snapshot is considered as a single sequence
    X.append(series)
    y.append(label)
  # Convert to numpy arrays for efficient processing
  return np.array(X), np.array(y)

train_data, val_data, test_data = datasets['train'], datasets['val'], datasets['test']


## The idea if to have x_train_i = [[[f1], [f2], [f3], ... , [fn]]] y_train_i = [[label_i]], f1 = feature vector of process 1 of snapshot i
## This is multivariate timeseries

## Single-variate (easily scaled to multi-variate): https://www.youtube.com/watch?v=c0k-YLQGKjY&ab_channel=GregHogg
## Multivariate (part 2) at: https://www.youtube.com/watch?v=kGdbPnMCdOg&ab_channel=GregHogg (26:00+)
 
# TODO: Use jupyter notebook with vs-code, so that I dont have to train new models every time

MAX_PROCESSES_LEN = 129 # The paper says 120 but there are some with 129
MAX_FEATURES_LEN = 210 # This is the number of features per process 


def tuple_dataset_to_X_y(dataset):
    X = []
    y = []
    for i in range(len(dataset)): # -1 ???
        row = dataset[i][0] # the i-th snapshot [[f0] [f1] [f2] ... [fn]] (vector of feature vectors/ aka multivariate timeseries)

        # Padding, 120 is the maximum number of processes as defined by the paper, but 129 is in the real dataset, and the minimum is 1
        while len(row) < MAX_PROCESSES_LEN:
            row.append(np.zeros(len(row[0])))

        X.append(row)
        label = dataset[i][1]
        y.append(label)


    # max_p = -1
    # max_p_index = -1
    # max_f = -1
    # max_f_j_index = -1
    # max_f_k_index = -1

    # for j in range(len(X)):
    #     if (len(X[j]) > max_p):
    #         max_p = len(X[j])
    #         max_p_index = j
    #     for k in range(len(X[j])):
    #         if len(X[j][k]) > max_f:
    #             max_f = len(X[j][k])
    #             max_f_k_index = k
    #             max_f_j_index = j

    # print(f'The maximum number of processes is {max_p} at index {max_p_index}')
    # print(f'The lengthiest number of features is {max_f} at j index {max_f_j_index} and k index {max_f_k_index}')
    # raise Exception('Stop here')

    return np.array(X), np.array(y)


x_train, y_train = tuple_dataset_to_X_y(datasets['train'])
x_val, y_val = tuple_dataset_to_X_y(datasets['val'])
x_test, y_test = tuple_dataset_to_X_y(datasets['test'])

print(x_train.shape)
print(y_train.shape)
print(x_val.shape)
print(y_val.shape)
print(x_test.shape)
print(y_test.shape)

# Now create train, validation, and test series with appropriate structure
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt


model1 = Sequential()
model1.add(InputLayer((MAX_PROCESSES_LEN, MAX_FEATURES_LEN)))
# model1.add(LSTM(64, return_sequences=True))  # Consider stacking LSTMs for complex data # TODO: Test without return_sequences
# model1.add(Dropout(0.2))  # Add dropout for regularization # TODO: Test without
model1.add(LSTM(64))  # Another LSTM layer (optional) # TODO: Test without
model1.add(Dense(8, activation='relu'))
model1.add(Dense(1, activation='sigmoid'))  # Use sigmoid for binary classification

model1.summary()

# TODO: Need to tune the aforementioned and also I am not sure they used the same architecture
# TODO: Also maybe use the 120 and prune the ones with more than 120
# TODO: Check that the data grouped together by the correct label, or fin another way to group them

model1.compile(loss=BinaryCrossentropy(), optimizer=Adam(learning_rate=1e-3), metrics=['accuracy'])

# Train the model with batch size of 32, 40 epochs from the paper
history = model1.fit(x_train, y_train, epochs=40, batch_size=32, validation_data=(x_val, y_val))

# Evaluate the model on the test set
test_loss, test_acc = model1.evaluate(x_test, y_test)
print('Test accuracy:', test_acc)

# Use classification metrics from scikit-learn
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

y_pred = model1.predict(x_test)  # Predict class probabilities
y_pred_classes = np.argmax(y_pred, axis=-1)  # Get class labels (index of max probability)


print('Y_pred = ', y_pred)

print(f'Ytest type = {type(y_test)}, y_pred type = {y_pred}')
y_test.shape
raise Exception('Stop here')

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print('Accuracy:', accuracy)
print('Precision:', precision)
print('Recall:', recall)
print('F1 Score:', f1)

# Extract training and validation loss data from history
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# Plot the training and validation loss curves
plt.plot(train_loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Model Loss (Binary Crossentropy)')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# raise Exception('Stop here')

# train_series = []
# for series_data in datasets['train']:
#   sequence = series_data[0]  # Access resource usage values
#   label = series_data[1]  # Access class label
#   train_series.append((sequence, label))

# val_series = []  # Create validation series similarly
# test_series = []  # Create test series similarly

# # Extract features (sequences) and labels from series
# train_X, train_y = zip(*train_series)
# val_X, val_y = zip(*val_series)
# test_X, test_y = zip(*test_series)

# # Determine vocabulary size (assuming all features are numerical)
# vocabulary_size = len(set([item for sublist in train_X for item in sublist])) + 1  # +1 for padding

# # Define the RNN model (replace with your desired architecture)
# model = keras.Sequential([
#   Embedding(vocabulary_size, embedding_dim=16, input_length=120),  # Adjust embedding dimension if needed
#   LSTM(64, return_sequences=True),  # Adjust number of units
#   LSTM(32),
#   Dense(1, activation='sigmoid')  # For binary classification
# ])

# # Compile the model with specified learning rate
# model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=1e-5), metrics=['accuracy'])

# # Train the model with batch size of 32
# model.fit(train_X, train_y, epochs=10, batch_size=32, validation_data=(val_X, val_y))  # Adjust epochs as needed

# # Evaluate the model on test data
# model.evaluate(test_X, test_y)


# print(datasets['val'][0])

# Now each element within datasets['train'/'val'/'test'] contains a list of N 2x1 tuples, where N is the number of samples aka series.
# Each tuple contains in its first place (tuple[0]) a list containing the number of processes at the given timestamp. This list has a maximum
# length of 120 (rows) where each row is a list of numericals, each numerical representing the value of a feature for the process.
# The second place of the tuple (tuple[1]) contains the class label of the series as a numerical.



# from tensorflow import keras
# from tensorflow.keras.layers import LSTM, Dense, Embedding
# # from tensorflow.keras.preprocessing.sequence import pad_sequence
# import tensorflow as tf

# # Assuming your datasets dictionary holds training, validation and test data

# # Define the function to create series with padding
# def create_series(df, max_len=120):
#     series_data = []
#     for experiment_id, group in df.groupby('experiment_id'):
#         snapshots = group.groupby('sample_time')
#         for timestamp, snapshot in snapshots:
#             # Check for different labels
#             if snapshot['label'].nunique() > 1:
#                 raise ValueError("Snapshot contains different labels")
#             label = 1 if any(snapshot['label']) else 0
#             sequence = snapshot.drop(columns=['sample_time', 'experiment_id', 'label']).values.tolist()
#             # Pad or truncate sequence to max_len
#             padded_sequence = tf.keras.utils.pad_sequences(sequence, max_len=max_len, padding='post', value=0.0)  # Pad with zeros at the end
#             series_data.append((padded_sequence, label))
#     return series_data

# # Create series for train, validation and test data with padding
# train_series = create_series(datasets['train'], max_len=120)
# val_series = create_series(datasets['val'], max_len=120)
# test_series = create_series(datasets['test'], max_len=120)

# # Extract features (sequences) and labels from series
# train_X, train_y = zip(*train_series)
# val_X, val_y = zip(*val_series)
# test_X, test_y = zip(*test_series)

# # Determine vocabulary size (assuming all features are numerical)
# # You might need to adjust this based on your data
# vocabulary_size = len(set([item for sublist in train_X for item in sublist])) + 1  # +1 for padding

# max_len = 120 # ???

# # Define the RNN model (replace with your desired architecture)
# model = keras.Sequential([
#     Embedding(vocabulary_size, embedding_dim=16, input_length=max_len),  # Adjust embedding dimension if needed
#     LSTM(64, return_sequences=True),  # Adjust number of units
#     LSTM(32),
#     Dense(1, activation='sigmoid')  # For binary classification
# ])

# # Compile the model with specified learning rate
# model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=1e-5), metrics=['accuracy'])

# # Train the model with batch size of 32
# model.fit(train_X, train_y, epochs=10, batch_size=32, validation_data=(val_X, val_y))  # Adjust epochs as needed

# # Evaluate the model on test data
# model.evaluate(test_X, test_y)


################################# Debug #################################
# import csv

# output_filename = "val_series_data.csv"
# series_data = datasets['val'][0][0]  # Get the series data from the first tuple in datasets['val']
# label = datasets['val'][0][1]  # Get the label from the first tuple in datasets['val']

# with open(output_filename, 'w', newline='') as csvfile:
#     writer = csv.writer(csvfile)
    
#     # Write the header row
#     writer.writerow(["timestamp"] + [f"feature_{i}" for i in range(len(series_data[0]))] + ["label"])
    
#     # Write each data point
#     for timestamp, data_point in enumerate(series_data):
#         writer.writerow([timestamp] + data_point + [label])

# print(f"Series data written to {output_filename}")

################################# Debug #################################
# output_folder = "series_data_csv"

# # Create the output folder if it doesn't exist
# os.makedirs(output_folder, exist_ok=True)

# for i, (series, label) in enumerate(series_data):
#     output_filename = os.path.join(output_folder, f"series_{i}.csv")
#     with open(output_filename, 'w') as f:
#         f.write("timestamp," + ",".join([f"feature_{j}" for j in range(len(series[0]))]) + ",label\n")
#         for timestamp, data_point in enumerate(series):
#             f.write(f"{timestamp}," + ",".join(map(str, data_point)) + f",{label}\n")
#     print(f"Series data written to {output_filename}")
################################# Debug #################################


############################### RNN Train ###############################


# Split the datasets into training, validation, and test sets
# train_data = datasets['train']
# val_data = datasets['val']
# test_data = datasets['test']

# # Unpack the data
# x_train, y_train = zip(*train_data)
# x_val, y_val = zip(*val_data)
# x_test, y_test = zip(*test_data)

# print(type(y_train))
# print(len(y_train))
# print(y_train)

# Convert data to numpy arrays
# import numpy as np
# x_train = np.array(x_train)
# y_train = np.array(y_train)
# x_val = np.array(x_val)
# y_val = np.array(y_val)
# x_test = np.array(x_test)
# y_test = np.array(y_test)

# # Define the maximum sequence length
# max_sequence_length = x_train.shape[1]

# # Define the RNN model
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import Embedding, SimpleRNN, Dense

# embedding_dim = 100  # Example embedding dimension
# num_classes = 2  # Assuming binary classification

# model = Sequential([
#     Embedding(input_dim=vocabulary_size, output_dim=embedding_dim, input_length=max_sequence_length),
#     SimpleRNN(units=64, activation='tanh'),  # Adjust units and activation function as needed
#     Dense(units=num_classes, activation='softmax')
# ])

# # Compile the model
# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# # Train the model
# model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))

# # Evaluate on test data
# test_loss, test_accuracy = model.evaluate(x_test, y_test)
# print("Test Accuracy:", test_accuracy)












# x_val = [data[0] for data in val_data]
# y_val = [data[1] for data in val_data]

# x_test = [data[0] for data in test_data]
# y_test = [data[1] for data in test_data]

# # Preprocess the data (padding sequences if necessary)
# max_sequence_length = 120  # Set the maximum sequence length to 120
# x_train = pad_sequences(x_train, maxlen=max_sequence_length, padding='post')
# x_val = pad_sequences(x_val, maxlen=max_sequence_length, padding='post')
# x_test = pad_sequences(x_test, maxlen=max_sequence_length, padding='post')

# # Define the RNN model
# model = Sequential([
#     Embedding(input_dim=vocabulary_size, output_dim=embedding_dim, input_length=max_sequence_length),
#     SimpleRNN(units=64, activation='tanh', return_sequences=False),  # You can also try LSTM or GRU here
#     Dense(units=num_classes, activation='softmax')
# ])

# # Compile the model
# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# # Train the model
# model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))

# # Evaluate on test data
# test_loss, test_accuracy = model.evaluate(x_test, y_test)
# print("Test Accuracy:", test_accuracy)



# Step 3: Create the sequences

# Step 4: Split into train, validation and test
    
# Step 5: Train and tune the model
    
# Step 6: Test the model

# Δες τη minimum redundancy maximum relevance.