import sys
import random

python3_path = sys.executable
print("Python 3 interpreter being used:", python3_path)

import os
import pandas as pd
from sklearn.model_selection import train_test_split
import math
import numpy as np
import keras
from keras import layers
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pickle

# Define samples fraction for decreasing dataset length
SAMPLES_FRACTION = 0.1 # 0.1

# Directory to save checkpoints
CHECKPOINT_DIR = 'checkpoints/transformer_vs_lstm/variable_dataset_len/1_10'
FILE_NAME = 'experiment1_200epochs_patience20_dataset_1_10.pkl'
IMAGE_DIR = 'images/transformer_vs_lstm/variable_dataset_len/1_10'
BEST_TRANSFORMER_CPT = "best_model_TRANSFORMER.keras"
BEST_LSTM_CPT = "best_model_LSTM.keras"

# Define Training, Validation, Test sizes
SAMPLE_NO = 104 #8
TRAIN_SIZE = math.floor(SAMPLE_NO*0.6)
VALIDATION_SIZE = math.ceil(SAMPLE_NO*0.2)
TEST_SIZE = math.ceil(SAMPLE_NO*0.2)

if TRAIN_SIZE + VALIDATION_SIZE + TEST_SIZE != SAMPLE_NO:
    raise Exception(f"Bad dataset size:\nSample Number: {SAMPLE_NO}\nTrain Size: {TRAIN_SIZE}\nValidation Size: {VALIDATION_SIZE}\nTest Size: {TEST_SIZE}")

# Read each preprocessed CSV file representing an experiment
data_path = os.path.join(os.getcwd(), 'preprocessed')
csv_files = os.listdir(data_path)[:SAMPLE_NO] # Use only the first SAMPLE_NO (for testing the training.py)
dfs = [pd.read_csv(os.path.join(data_path, file)) for file in csv_files] # A list of dfs, 1 csv = 1 df

# Drop specified columns from all dataframes
columns_to_drop = [
'sample_no', 'exp_no', 'vm_id', 'pid', 'ppid', 'process_creation_time', 'gid_real',
'gid_saved', 'mem_pss', #'experiment_id' , 'sample_time', 'label' # These three are dropped later
] 

# Drop unecessary columns
for df in dfs:
    df.drop(columns=columns_to_drop, inplace=True)
    df.drop(columns=[s for s in df.columns if s.startswith("name_")], inplace=True) # DROP THE 'name' feature

print(dfs[0].columns)
print(len(dfs[0].columns))

# Split data by experiment into training, validation, and testing sets
train_experiments, test_experiments = train_test_split(csv_files, test_size=(TEST_SIZE+VALIDATION_SIZE), random_state=42)
val_experiments, test_experiments = train_test_split(test_experiments, test_size=TEST_SIZE, random_state=42)

print('Train:', train_experiments)
print('Validation', val_experiments)
print('Test:', test_experiments)

# Collect data for each set and transform into series format
datasets = {}
for split, experiments in zip(["train", "val", "test"], [train_experiments, val_experiments, test_experiments]): # (('train', [1, 2]), ('val', [3]), ('test', [4]))
    
    # data contains the concatenated train/validation/test dataframe in the respective iteration (3 iterations)
    data = pd.concat([dfs[csv_files.index(exp)] for exp in experiments]) 

    series_data = []
    for experiment_id, df in data.groupby('experiment_id'): # Per each dataframe (train, validation, test) group by experiment id
        snapshots = df.groupby('sample_time') # And then group by sample time per each experiment
        for timestamp, group in snapshots:

            # Check if all labels within the snapshot are the same
            if group['label'].nunique() > 1:
                raise ValueError("Snapshot contains different labels")
            
            # Determine the class label for the snapshot
            label = 1 if any(group['label']) else 0
            
            # Append a tuple containing series data and label
            series = group.drop(columns=['sample_time', 'experiment_id', 'label']).values.tolist()
            series_data.append((series, label))

    # Apply the sampling fraction
    sampled_series_data = random.sample(series_data, int(len(series_data) * SAMPLES_FRACTION))
    datasets[split] = sampled_series_data

    if len(datasets[split]) != int(pd.concat([dfs[csv_files.index(exp)] for exp in experiments])['sample_time'].unique().size * SAMPLES_FRACTION):
        raise ValueError(f"Series sample number are not the same for split: {split}")

    print(f'Split: {split} sample size: ', len(datasets[split]))


"""
    - datasets -> dict: A dictionary containing the data splitted in training, validation, test set
    - datasets.train/val/test -> list: A list of tuples, each one containing:
    - datasets.train/val/test[0] -> tuple: Tuple i
    - datasets.train/val/test[i][0] -> list: snapshot/subsamples list of the i-th tuple/snapshot
    - datasets.train/val/test[i][1] -> int: label of the i-th tuple/snapshot
    - datasets.train/val/test[i][j][0] -> int: feature vector of the j-th process and the i-th tuple/snapshot

    -- Each tuple refers to a specific snapshot on a given timestamp of the system processes. The label of the tuple
    states whether the system was infected at that time or not. 
    -- (the concept of experiment_id is used up until splitting
    into train/validation/test where all the snapshots from the same experiment are maintained within one of train/val/test
    and not splitted. After that, the experiment_id concept is deprecated)
    -- The infectious process is probably the one that has the same name with the csv -> TODO: Implement this later.
"""

print('Datasets keys: ', datasets.keys())
print(type(datasets['val'])) # Validation List
print(len(datasets['val']))
print(type(datasets['val'][0])) # A snapshot/sample tuple (subsamples list, label)
print(len(datasets['val'][0]))
print(type(datasets['val'][0][0])) # Subsamples list
print(len(datasets['val'][0][0]))
print(type(datasets['val'][0][0][0])) # Feature vector of a specific process at a specific timestamp/snapshot/sample
print(len(datasets['val'][0][0][0]))
datasets['train'][0][0]



def prepare_data(data):
    """
    Prepares data for LSTM training.

    Args:
      data: A list of tuples containing (series, label).
          - series: A list of lists, where each inner list represents features 
                    of all processes at a specific timestamp within the snapshot.
          - label: An integer representing the class label (0 or 1) for the entire snapshot.

    Returns:
      A tuple containing two numpy arrays:
          - X: Input data for the LSTM, shaped (samples, feature_dim).
          - y: Labels, shaped (samples,).
    """
    X, y = [], []
    for series, label in data:
        # Get the number of features per process (assuming all processes have the same)
        feature_dim = len(series[0])
        # The entire snapshot is considered as a single sequence
        X.append(series)
        y.append(label)

    # Convert to numpy arrays for efficient processing
    return np.array(X), np.array(y)

train_data, val_data, test_data = datasets['train'], datasets['val'], datasets['test']

## The idea if to have x_train_i = [[[f1], [f2], [f3], ... , [fn]]] y_train_i = [[label_i]], f1 = feature vector of process 1 of snapshot i
## This is multivariate timeseries

## Single-variate (easily scaled to multi-variate): https://www.youtube.com/watch?v=c0k-YLQGKjY&ab_channel=GregHogg
## Multivariate (part 2) at: https://www.youtube.com/watch?v=kGdbPnMCdOg&ab_channel=GregHogg (26:00+)

MAX_PROCESSES_LEN = 227 # The paper says 120 but there are some with 190
MAX_FEATURES_LEN = 34 # This is the number of features per process 

def tuple_dataset_to_X_y(dataset, one_hot_encode=False):
    X = []
    y = []
    for i in range(len(dataset)): # -1 ???
        row = dataset[i][0] # the i-th snapshot [[f0] [f1] [f2] ... [fn]] (vector of feature vectors/ aka multivariate timeseries)
        
        # Padding, 120 is the maximum number of processes as defined by the paper, but 131 is in the real dataset, and the minimum is 1
        while len(row) < MAX_PROCESSES_LEN:
            row.append(np.zeros(len(row[0])))

        X.append(row)
        label = dataset[i][1]
        y.append(label)

    # One hot encode labels if required
    if one_hot_encode:
        y_np = np.array(y)
        y = np.eye(2)[y_np]

    length = len(X[0])
    print('Length X:', len(X))
    for i in range(len(X)):
        if len(X[i]) != length:
            raise Exception(f'Length X[{i}]: {len(X[i])} is different than length: {length}')

    return np.array(X), np.array(y)

x_train, y_train = tuple_dataset_to_X_y(datasets['train'])
x_val, y_val = tuple_dataset_to_X_y(datasets['val'])
x_test, y_test = tuple_dataset_to_X_y(datasets['test'])

print('Data shapes')
print(x_train.shape)
print(y_train.shape)
print(x_val.shape)
print(y_val.shape)
print(x_test.shape)
print(y_test.shape)
print(y_train)
print(y_train.tolist().count(0))
print(y_train.tolist().count(1))

EPSILON = 1e-6

def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):
    # Attention and Normalization
    x = layers.MultiHeadAttention(
        key_dim=head_size, num_heads=num_heads, dropout=dropout
    )(inputs, inputs)
    x = layers.Dropout(dropout)(x)
    x = layers.LayerNormalization(epsilon=1e-6)(x)
    res = x + inputs

    # Feed Forward Part
    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation="relu")(res)
    x = layers.Dropout(dropout)(x)
    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)
    x = layers.LayerNormalization(epsilon=1e-6)(x)
    return x + res

def build_model(
    input_shape,
    head_size,
    num_heads,
    ff_dim,
    num_transformer_blocks,
    mlp_units,
    dropout=0,
    mlp_dropout=0,
    n_classes=2
):
    inputs = keras.Input(shape=input_shape)
    x = inputs
    for _ in range(num_transformer_blocks):
        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)

    x = layers.GlobalAveragePooling1D(data_format="channels_last")(x)
    for dim in mlp_units:
        x = layers.Dense(dim, activation="relu")(x)
        x = layers.Dropout(mlp_dropout)(x)
    outputs = layers.Dense(n_classes, activation="softmax")(x)
    return keras.Model(inputs, outputs)

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import KFold
from scipy.stats import ttest_rel
import os
from multiprocessing import Process, Manager
import time

def evaluate_model_transformer(params, x_train, y_train, x_val, y_val, x_test, y_test):
    input_shape = x_train.shape[1:]

    model = build_model(
        input_shape,
        head_size=params['head_size'],
        num_heads=params['num_heads'],
        ff_dim=params['ff_dim'],
        num_transformer_blocks=params['num_transformer_blocks'],
        mlp_units=params['mlp_units'],
        mlp_dropout=params['dropout'],
        dropout=params['dropout'],
    )

    model.compile(
        loss="sparse_categorical_crossentropy",
        optimizer=keras.optimizers.Adam(learning_rate=params['learning_rate']),
        metrics=["sparse_categorical_accuracy"],
    )

    callbacks = [
        keras.callbacks.ModelCheckpoint(
            BEST_TRANSFORMER_CPT, save_best_only=True, monitor="val_loss"
        ),
        keras.callbacks.EarlyStopping(
            monitor='val_loss', patience=params['patience'], restore_best_weights=True
        ),
    ]

    start_time = time.time()
    history = model.fit(
        x_train,
        y_train,
        epochs=params['epochs'],
        batch_size=params['batch_size'],
        callbacks=callbacks,
        validation_data=(x_val, y_val),
        verbose=2
    )
    end_time = time.time()
    
    training_time = end_time - start_time

    # test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)
    y_pred = model.predict(x_test, verbose=2)
    y_pred_classes = np.argmax(y_pred, axis=-1)

    accuracy = accuracy_score(y_test, y_pred_classes)
    precision = precision_score(y_test, y_pred_classes)
    recall = recall_score(y_test, y_pred_classes)
    f1 = f1_score(y_test, y_pred_classes)

    return accuracy, precision, recall, f1, history.history, model, training_time

def run_evaluation_transformer(params, x_train, y_train, x_val, y_val, x_test, y_test, return_dict, models_rnn):
    accuracy, precision, recall, f1, history, model, training_time = evaluate_model_transformer(params, x_train, y_train, x_val, y_val, x_test, y_test)
    return_dict['accuracy'] = accuracy
    return_dict['precision'] = precision
    return_dict['recall'] = recall
    return_dict['f1'] = f1
    return_dict['history'] = history
    return_dict['training_time'] = training_time
    models_rnn.append(model)
    keras.backend.clear_session()  # Free GPU VRAM

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy
from sklearn.model_selection import ParameterGrid
import numpy as np

# Function to create and train model for a given set of hyperparameters
# def create_and_train_model_LSTM(batch_size, learning_rate, x_train, y_train, x_val, y_val):
def evaluate_model_lstm(params, x_train, y_train, x_val, y_val, x_test, y_test):
    model = Sequential()
    model.add(InputLayer((MAX_PROCESSES_LEN, MAX_FEATURES_LEN)))
    model.add(LSTM(256, return_sequences=True))
    model.add(Dropout(0.1))
    model.add(LSTM(128, return_sequences=True))
    model.add(Dropout(0.1))
    model.add(LSTM(64))
    model.add(Dropout(0.1))
    model.add(Dense(2, activation="softmax"))
    model.compile(loss="sparse_categorical_crossentropy", optimizer=Adam(learning_rate=params['learning_rate']), metrics=['sparse_categorical_accuracy'])
    
    callbacks = [
        keras.callbacks.ModelCheckpoint(
            BEST_LSTM_CPT, save_best_only=True, monitor="val_loss"
        ),
        keras.callbacks.EarlyStopping(
            monitor='val_loss', patience=params['patience'], restore_best_weights=True
        ),
    ]
    
    start_time = time.time()
    history = model.fit(
        x_train, 
        y_train, 
        epochs=params['epochs'], 
        batch_size=params['batch_size'],
        callbacks=callbacks,
        validation_data=(x_val, y_val),
        verbose=2
    )
    end_time = time.time()
    
    training_time = end_time - start_time

    # test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)
    y_pred = model.predict(x_test, verbose=2)
    y_pred_classes = np.argmax(y_pred, axis=-1)

    accuracy = accuracy_score(y_test, y_pred_classes)
    precision = precision_score(y_test, y_pred_classes)
    recall = recall_score(y_test, y_pred_classes)
    f1 = f1_score(y_test, y_pred_classes)

    return accuracy, precision, recall, f1, history.history, model, training_time

def run_evaluation_lstm(params, x_train, y_train, x_val, y_val, x_test, y_test, return_dict, models_rnn):
    accuracy, precision, recall, f1, history, model, training_time = evaluate_model_lstm(params, x_train, y_train, x_val, y_val, x_test, y_test)
    return_dict['accuracy'] = accuracy
    return_dict['precision'] = precision
    return_dict['recall'] = recall
    return_dict['f1'] = f1
    return_dict['history'] = history
    return_dict['training_time'] = training_time
    models_rnn.append(model)
    keras.backend.clear_session()  # Free GPU VRAM

# TODO: CORRECT THESE VALUES
EPOCHS = 200
PATIENCE = 20
FOLDS = 10

TRANSFORMER_MODEL = {
    'num_transformer_blocks': 4,
    'head_size': 128,
    'num_heads': 6,
    'ff_dim': 512,
    'learning_rate': 0.001,
    'mlp_units': [128],
    'dropout': 0.1,
    'batch_size': 96,
    'epochs': EPOCHS,
    'patience': PATIENCE
}

# TODO: Find the optimum of the following
LSTM_MODEL = {
    'batch_size': 16,
    'learning_rate': 1e-05,
    'epochs': EPOCHS,
    'patience': PATIENCE
}

MODELS = {
    'TRANSFORMER': TRANSFORMER_MODEL,
    'LSTM': LSTM_MODEL
}

os.makedirs(CHECKPOINT_DIR, exist_ok=True)

# Function to save checkpoints
def save_checkpoint(filename, data):
    with open(os.path.join(CHECKPOINT_DIR, filename), 'wb') as f:
        pickle.dump(data, f)

# Function to load checkpoints
def load_checkpoint(filename):
    if os.path.exists(os.path.join(CHECKPOINT_DIR, filename)):
        with open(os.path.join(CHECKPOINT_DIR, filename), 'rb') as f:
            return pickle.load(f)
    return None

# Perform K-Fold Cross-Validation
kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)

# Collect metrics for both models
model_metrics = {key: {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'training_time': []} for key in MODELS.keys()}
histories = {key: [] for key in MODELS.keys()}

# Load saved state if available
saved_state = load_checkpoint(FILE_NAME)
current_fold = 0
if saved_state:
    model_metrics, histories, current_fold = saved_state
else:
    current_fold = 0

x_data = np.concatenate((x_train, x_val, x_test), axis=0)
y_data = np.concatenate((y_train, y_val, y_test), axis=0)

manager = Manager()
return_dict = manager.dict()
manager2 = Manager()
models_rnn = manager2.list()

for fold_index, (train_index, val_index) in enumerate(kf.split(x_data)):
    if fold_index < current_fold:
        print('Checkpoint found, skipping fold:', fold_index)
        continue  # Skip already processed folds

    x_fold_train, x_fold_val = x_data[train_index], x_data[val_index]
    y_fold_train, y_fold_val = y_data[train_index], y_data[val_index]

    for key, params in MODELS.items():
        keras.backend.clear_session()
        print(f'Training {key} in FOLD: {fold_index}, with parameters:', params)
        time.sleep(5)

        if key == 'TRANSFORMER':
            p = Process(target=run_evaluation_transformer, args=(params, x_fold_train, y_fold_train, x_fold_val, y_fold_val, x_fold_val, y_fold_val, return_dict, models_rnn))
        elif key == 'LSTM':
            p = Process(target=run_evaluation_lstm, args=(params, x_fold_train, y_fold_train, x_fold_val, y_fold_val, x_fold_val, y_fold_val, return_dict, models_rnn))
        
        p.start()
        p.join()  # Wait for the subprocess to finish
        # p.kill()

        accuracy = return_dict['accuracy']
        precision = return_dict['precision']
        recall = return_dict['recall']
        f1 = return_dict['f1']
        history = return_dict['history']
        training_time = return_dict['training_time']

        
        model_metrics[key]['accuracy'].append(accuracy)
        model_metrics[key]['precision'].append(precision)
        model_metrics[key]['recall'].append(recall)
        model_metrics[key]['f1'].append(f1)
        model_metrics[key]['training_time'].append(training_time)
        histories[key].append(history)

    # Save state after each fold
    current_fold += 1
    save_checkpoint(FILE_NAME, (model_metrics, histories, current_fold))

# Perform t-tests to compare models
model_keys = list(MODELS.keys())
for i in range(len(model_keys)):
    for j in range(i + 1, len(model_keys)):
        key1 = model_keys[i]
        key2 = model_keys[j]

        print(f'\nComparing {key1} vs {key2}:')

        accuracy_ttest = ttest_rel(model_metrics[key1]['accuracy'], model_metrics[key2]['accuracy'])
        precision_ttest = ttest_rel(model_metrics[key1]['precision'], model_metrics[key2]['precision'])
        recall_ttest = ttest_rel(model_metrics[key1]['recall'], model_metrics[key2]['recall'])
        f1_ttest = ttest_rel(model_metrics[key1]['f1'], model_metrics[key2]['f1'])
        training_time_ttest = ttest_rel(model_metrics[key1]['training_time'], model_metrics[key2]['training_time'])

        print(f"Accuracy t-test: p-value={accuracy_ttest.pvalue}")
        print(f"Precision t-test: p-value={precision_ttest.pvalue}")
        print(f"Recall t-test: p-value={recall_ttest.pvalue}")
        print(f"F1-score t-test: p-value={f1_ttest.pvalue}")
        print(f"Training time t-test: p-value={training_time_ttest.pvalue}")

import matplotlib.pyplot as plt

for key, fold_histories in histories.items():
    metric = "sparse_categorical_accuracy"

    BATCH_SIZE = MODELS[key]['batch_size']
    LEARNING_RATE = MODELS[key]['learning_rate']
    PARAMS = MODELS[key].copy()
    PARAMS.pop('batch_size', None)
    PARAMS.pop('learning_rate', None)
    
    for fold_index, history in enumerate(fold_histories):
        plt.figure()
        plt.plot(history['sparse_categorical_accuracy'])
        plt.plot(history["val_sparse_categorical_accuracy"])
        plt.title(f"Sparse Categorical Accuracy {key.lower()} - Fold {fold_index+1}")
        plt.ylabel("Sparse Categorical Accuracy", fontsize="large")
        plt.xlabel("Epoch", fontsize="large")
        plt.legend(["Train", "Validation"], loc="best")
        plt.savefig(f'{IMAGE_DIR}/training_{key.lower()}_accuracy_fold{fold_index+1}_epochs{EPOCHS}_BS{BATCH_SIZE}_LR{LEARNING_RATE}.jpg')
        plt.show()
        plt.close()

    metric = "loss"

    for fold_index, history in enumerate(fold_histories):
        plt.figure()
        plt.plot(history['loss'])
        plt.plot(history["val_loss"])
        plt.title(f"Training and Validation Loss {key.lower()} - Fold {fold_index+1}")
        plt.ylabel("Loss", fontsize="large")
        plt.xlabel("Epoch", fontsize="large")
        plt.legend(["Train", "Validation"], loc="best")
        plt.savefig(f'{IMAGE_DIR}/training_{key.lower()}_loss_fold{fold_index+1}_epochs{EPOCHS}_BS{BATCH_SIZE}_LR{LEARNING_RATE}.jpg')
        plt.show()
        plt.close()


# Calculate and print average metrics and training time
from statistics import mean

for model_name, metrics in model_metrics.items():

    print(f"\n{model_name} metrics:")
    print('Accuracy:', model_metrics[model_name]['accuracy'])
    print('Precision:', model_metrics[model_name]['precision'])
    print('Recall:', model_metrics[model_name]['recall'])
    print('F1-score:', model_metrics[model_name]['f1'])
    print('Training Time (s):', metrics['training_time'])

import statistics

for model_name, metrics in model_metrics.items():
    print(f"\n{model_name} average metrics:")

    accuracy_mean = statistics.mean(metrics['accuracy'])
    accuracy_median = statistics.median(metrics['accuracy'])
    accuracy_std = statistics.stdev(metrics['accuracy'])
    print('Accuracy: Mean =', accuracy_mean, 'Median =', accuracy_median, 'Std =', accuracy_std)

    precision_mean = statistics.mean(metrics['precision'])
    precision_median = statistics.median(metrics['precision'])
    precision_std = statistics.stdev(metrics['precision'])
    print('Precision: Mean =', precision_mean, 'Median =', precision_median, 'Std =', precision_std)

    recall_mean = statistics.mean(metrics['recall'])
    recall_median = statistics.median(metrics['recall'])
    recall_std = statistics.stdev(metrics['recall'])
    print('Recall: Mean =', recall_mean, 'Median =', recall_median, 'Std =', recall_std)

    f1_mean = statistics.mean(metrics['f1'])
    f1_median = statistics.median(metrics['f1'])
    f1_std = statistics.stdev(metrics['f1'])
    print('F1-score: Mean =', f1_mean, 'Median =', f1_median, 'Std =', f1_std)

    training_time_mean = statistics.mean(metrics['training_time'])
    training_time_median = statistics.median(metrics['training_time'])
    training_time_std = statistics.stdev(metrics['training_time'])
    print('Average Training Time (s): Mean =', training_time_mean, 'Median =', training_time_median, 'Std =', training_time_std)



def find_first_less_than(arr, threshold):
    return next((i for i, value in enumerate(arr) if value < threshold), EPOCHS)

def find_first_greater_than(arr, threshold):
    return next((i for i, value in enumerate(arr) if value > threshold), EPOCHS)

for model in histories.keys():
    val_index_loss = 0
    val_index_acc = 0
    for fold in histories[model]:
        temp = find_first_less_than(fold['val_loss'], 0.1)
        val_index_loss += temp
        temp = find_first_greater_than(fold['val_sparse_categorical_accuracy'], 0.95)
        val_index_acc += temp

    print(f'\nAverage Index for {model} where val_loss < 0.1:', val_index_loss / FOLDS)
    print(f'Average Index for {model} where val_acc > 0.95:', val_index_acc / FOLDS)

