# Original Code: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly

import numpy as np
import keras
import os

class DataGenerator(keras.utils.Sequence):
    'Generates data for Keras'
    def __init__(self, list_IDs, dim=(227, 34), batch_size=32, n_channels=1, shuffle=True, data_folder = ''):
        """
        Initialization
        
        Parameters
        ----------
        
        dim : tuple of int, optional
            Dimensions of each input sample, probably
        n_channels : int, optional
            Number of values of each feature per timestamp ("227 timestamps"), which is 1 for my data.
        shuffle : bool, optional
            Whether to shuffle the samples after each epoch (default is True).
            True to perform the same experiment, model.fit shuffles by default (https://datascience.stackexchange.com/questions/67495/will-keras-fit-function-automatically-shuffles-the-input-dataset-by-default)
        """
        self.list_IDs = list_IDs
        self.dim = dim # (227, 34)
        self.batch_size = batch_size
        # self.labels = labels # We load them from the disk too
        self.n_channels = n_channels # 1
        # self.n_classes = n_classes We don't need categorical data
        self.shuffle = shuffle # True
        self.data_folder = data_folder
        self.on_epoch_end()

    def __len__(self):
        'Denotes the number of batches per epoch'
        return int(np.floor(len(self.list_IDs) / self.batch_size))

    def __getitem__(self, index):
        'Generate one batch of data'
        # Generate indexes of the batch
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]

        # Find list of IDs
        list_IDs_temp = [self.list_IDs[k] for k in indexes]

        # Generate data
        X, y = self.__data_generation(list_IDs_temp)

        return X, y

    def on_epoch_end(self):
        'Updates indexes after each epoch'
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def __data_generation(self, list_IDs_temp):
        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)
        # Initialization
        X = np.empty((self.batch_size, *self.dim))
        y = np.empty((self.batch_size), dtype=int)

        # Generate data
        for i, ID in enumerate(list_IDs_temp):
            # Store sample
            X[i,] = np.load(os.path.join(self.data_folder, 'X/') + str(ID) + '.npy')

            # Store class
            y[i] = np.load(os.path.join(self.data_folder, 'y/') + str(ID) + '.npy')

        return X, y #keras.utils.to_categorical(y, num_classes=self.n_classes)

    def getDim(self):
        return self.dim

""" 
Self notes:
    1) The number of steps per epoch is defined by the formula no_training_samples / model_batch_size
    for example if the total training samples are 25392 and the batch size is 96 then we have 
    264.5 ~ 265 steps per epoch (this is also proved by the transformer vs LSTM ttest experiment)

""" 
